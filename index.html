<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="InstructG2I is a graph context-conditioned diffusion model to generate images from multimodal attributed graphs (MMAGs).">
  <meta name="keywords" content="InstructG2I, diffusion models, graphs">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>InstructG2I: Synthesizing Images from Multimodal Attributed Graphs</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://peterjin.me">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs">
            LLMs on Graphs survey
          </a>
          <a class="navbar-item" href="https://github.com/PeterGriffinJin/Graph-CoT">
            Graph Chain-of-Thought
          </a>
          <a class="navbar-item" href="https://github.com/PeterGriffinJin/Patton">
            Patton
          </a>
          <a class="navbar-item" href="https://github.com/PeterGriffinJin/Edgeformers">
            Edgeformers
          </a>
          <a class="navbar-item" href="https://github.com/PeterGriffinJin/Heterformer">
            Heterformer
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">InstructG2I: Synthesizing Images from Multimodal Attributed Graphs</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://peterjin.me/">Bowen Jin</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ziqipang.github.io/">Ziqi Pang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Bingjun Guo</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yxw.cs.illinois.edu/">Yu-xiong Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://cs.stanford.edu/people/jiaxuan/">Jiaxuan You</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://hanj.cs.illinois.edu/">Jiawei Han</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Illinois at Urbana-Champaign</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/PeterGriffinJin/InstructG2I"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1HzMAHteJrkBYqq1yRfe6cTPTWxVLDCWq"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/PeterJinGo/VirtualArtist"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Model</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure class="image">
        <img src="./static/images/intro.png" alt="Teaser Image">
      </figure>
      <h2 class="subtitle has-text-centered">
        We propose a new task Graph2Image featuring image synthesis by conditioning on graph information and 
        introduce a novel graph-conditioned diffusion model called <b>InstructG2I</b> to tackle this problem.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this paper, we approach an overlooked yet critical task <b>Graph2Image</b>: generating images 
            from multimodal attributed graphs (MMAGs).
            This task poses significant challenges due to the explosion in graph size, dependencies among graph entities, 
            and the need for controllability in graph conditions. 
            To address these challenges, we propose a graph context-conditioned diffusion model called 
            <b>InstructG2I</b>.
            <b>InstructG2I</b> first exploits the graph structure and multimodal information to conduct informative 
            neighbor sampling by combining personalized page rank and re-ranking based on vision-language features. 
            Then, a Graph-QFormer encoder adaptively encodes the graph nodes into an auxiliary set of <b>graph prompts</b> 
            to guide the denoising process of diffusion. 
            Finally, we propose graph classifier-free guidance, enabling controllable generation by varying the 
            strength of graph guidance and multiple connected edges to a node.
            Extensive experiments conducted on three datasets from different domains demonstrate the 
            effectiveness and controllability of our approach. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Model Architecture. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Model Architecture</h2>

        <div class="column">
          <figure>
            <img src="./static/images/main.png" alt="Model Architecture">
            <figcaption>The overall framework of <b>InstructG2I</b>.</figcaption>
          </figure>
        </div>

        <div class="content has-text-justified"></div>
          <p>
            (a) Given a target node with a text prompt (e.g., House in Snow) in a Multimodal Attributed Graph (MMAG) 
            for which we want to generate an image, (b) we first perform semantic PPR-based neighbor sampling, 
            which involves structure- aware personalized PageRank and semantic-aware similarity-based reranking 
            to sample informative neighboring nodes in the graph. (c) These neighboring nodes are then inputted 
            into a Graph-QFormer, encoded by multiple self-attention and cross-attention layers, represented as 
            graph tokens and used to guide the denoising process of the diffusion model, together with text prompt tokens.
          </p>
        </div>
      
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      
      </div>
    </div>
    <!--/ Model Architecture. -->

    <!-- Concurrent Work.
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            It is borrowed from <a
            href="https://github.com/nerfies/nerfies.github.io">source code</a>.
            <!-- This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website. -->
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
